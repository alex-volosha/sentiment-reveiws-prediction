{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Package Name</th>\n",
       "      <th>App Version Code</th>\n",
       "      <th>App Version Name</th>\n",
       "      <th>Reviewer Language</th>\n",
       "      <th>Device</th>\n",
       "      <th>Review Submit Date and Time</th>\n",
       "      <th>Review Submit Millis Since Epoch</th>\n",
       "      <th>Review Last Update Date and Time</th>\n",
       "      <th>Review Last Update Millis Since Epoch</th>\n",
       "      <th>Star Rating</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Developer Reply Date and Time</th>\n",
       "      <th>Developer Reply Millis Since Epoch</th>\n",
       "      <th>Developer Reply Text</th>\n",
       "      <th>Review Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com.nick.memasik</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>surnia_umts</td>\n",
       "      <td>2018-12-01T00:00:54Z</td>\n",
       "      <td>1543622454139</td>\n",
       "      <td>2018-12-01T00:00:54Z</td>\n",
       "      <td>1543622454139</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com.nick.memasik</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3.0.1</td>\n",
       "      <td>es</td>\n",
       "      <td>cs02ve3gss</td>\n",
       "      <td>2018-12-01T00:25:28Z</td>\n",
       "      <td>1543623928849</td>\n",
       "      <td>2018-12-01T00:25:49Z</td>\n",
       "      <td>1543623949604</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ehhh.......</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://play.google.com/console/developers/4768...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com.nick.memasik</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3.0.1</td>\n",
       "      <td>es</td>\n",
       "      <td>j7xelte</td>\n",
       "      <td>2018-12-01T02:30:39Z</td>\n",
       "      <td>1543631439053</td>\n",
       "      <td>2018-12-01T02:32:07Z</td>\n",
       "      <td>1543631527535</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Esta aplicaci√≥n esta padrisima ojala que asi f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://play.google.com/console/developers/4768...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com.nick.memasik</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3.0.1</td>\n",
       "      <td>es</td>\n",
       "      <td>E1M</td>\n",
       "      <td>2018-12-01T02:40:37Z</td>\n",
       "      <td>1543632037870</td>\n",
       "      <td>2018-12-01T02:41:12Z</td>\n",
       "      <td>1543632072218</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Muy divertida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://play.google.com/console/developers/4768...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com.nick.memasik</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3.0.1</td>\n",
       "      <td>es</td>\n",
       "      <td>judyln</td>\n",
       "      <td>2018-12-01T03:12:48Z</td>\n",
       "      <td>1543633968769</td>\n",
       "      <td>2018-12-01T03:12:55Z</td>\n",
       "      <td>1543633975304</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62370</th>\n",
       "      <td>com.nick.memasik</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar</td>\n",
       "      <td>hwY635</td>\n",
       "      <td>2018-09-30T21:12:47Z</td>\n",
       "      <td>1538341967638</td>\n",
       "      <td>2018-09-30T21:12:52Z</td>\n",
       "      <td>1538341972314</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62371</th>\n",
       "      <td>com.nick.memasik</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>es</td>\n",
       "      <td>grandprimevelteltn</td>\n",
       "      <td>2018-09-30T21:43:03Z</td>\n",
       "      <td>1538343783391</td>\n",
       "      <td>2018-09-30T21:43:25Z</td>\n",
       "      <td>1538343805498</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Es un ascoo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://play.google.com/console/developers/4768...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62372</th>\n",
       "      <td>com.nick.memasik</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>es</td>\n",
       "      <td>a5xelte</td>\n",
       "      <td>2018-09-30T22:03:41Z</td>\n",
       "      <td>1538345021089</td>\n",
       "      <td>2018-09-30T22:03:41Z</td>\n",
       "      <td>1538345021089</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62373</th>\n",
       "      <td>com.nick.memasik</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>es</td>\n",
       "      <td>hwG610-U15</td>\n",
       "      <td>2018-09-30T22:29:47Z</td>\n",
       "      <td>1538346587066</td>\n",
       "      <td>2018-09-30T22:30:26Z</td>\n",
       "      <td>1538346626461</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62374</th>\n",
       "      <td>com.nick.memasik</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>HWCRO-L6737M</td>\n",
       "      <td>2018-09-30T23:08:41Z</td>\n",
       "      <td>1538348921855</td>\n",
       "      <td>2018-09-30T23:09:17Z</td>\n",
       "      <td>1538348957058</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aaaaaaaaaaa super bueno</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://play.google.com/console/developers/4768...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62375 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Package Name  App Version Code App Version Name Reviewer Language   \n",
       "0      com.nick.memasik               NaN              NaN                es  \\\n",
       "1      com.nick.memasik              95.0            3.0.1                es   \n",
       "2      com.nick.memasik              95.0            3.0.1                es   \n",
       "3      com.nick.memasik              95.0            3.0.1                es   \n",
       "4      com.nick.memasik              95.0            3.0.1                es   \n",
       "...                 ...               ...              ...               ...   \n",
       "62370  com.nick.memasik               NaN              NaN                ar   \n",
       "62371  com.nick.memasik              90.0              2.1                es   \n",
       "62372  com.nick.memasik              90.0              2.1                es   \n",
       "62373  com.nick.memasik              90.0              2.1                es   \n",
       "62374  com.nick.memasik               NaN              NaN                es   \n",
       "\n",
       "                   Device Review Submit Date and Time   \n",
       "0             surnia_umts        2018-12-01T00:00:54Z  \\\n",
       "1              cs02ve3gss        2018-12-01T00:25:28Z   \n",
       "2                 j7xelte        2018-12-01T02:30:39Z   \n",
       "3                     E1M        2018-12-01T02:40:37Z   \n",
       "4                  judyln        2018-12-01T03:12:48Z   \n",
       "...                   ...                         ...   \n",
       "62370              hwY635        2018-09-30T21:12:47Z   \n",
       "62371  grandprimevelteltn        2018-09-30T21:43:03Z   \n",
       "62372             a5xelte        2018-09-30T22:03:41Z   \n",
       "62373          hwG610-U15        2018-09-30T22:29:47Z   \n",
       "62374        HWCRO-L6737M        2018-09-30T23:08:41Z   \n",
       "\n",
       "       Review Submit Millis Since Epoch Review Last Update Date and Time   \n",
       "0                         1543622454139             2018-12-01T00:00:54Z  \\\n",
       "1                         1543623928849             2018-12-01T00:25:49Z   \n",
       "2                         1543631439053             2018-12-01T02:32:07Z   \n",
       "3                         1543632037870             2018-12-01T02:41:12Z   \n",
       "4                         1543633968769             2018-12-01T03:12:55Z   \n",
       "...                                 ...                              ...   \n",
       "62370                     1538341967638             2018-09-30T21:12:52Z   \n",
       "62371                     1538343783391             2018-09-30T21:43:25Z   \n",
       "62372                     1538345021089             2018-09-30T22:03:41Z   \n",
       "62373                     1538346587066             2018-09-30T22:30:26Z   \n",
       "62374                     1538348921855             2018-09-30T23:09:17Z   \n",
       "\n",
       "       Review Last Update Millis Since Epoch  Star Rating Review Title   \n",
       "0                              1543622454139            5          NaN  \\\n",
       "1                              1543623949604            3          NaN   \n",
       "2                              1543631527535            5          NaN   \n",
       "3                              1543632072218            5          NaN   \n",
       "4                              1543633975304            5          NaN   \n",
       "...                                      ...          ...          ...   \n",
       "62370                          1538341972314            3          NaN   \n",
       "62371                          1538343805498            1          NaN   \n",
       "62372                          1538345021089            3          NaN   \n",
       "62373                          1538346626461            5          NaN   \n",
       "62374                          1538348957058            5          NaN   \n",
       "\n",
       "                                             Review Text   \n",
       "0                                                    NaN  \\\n",
       "1                                            Ehhh.......   \n",
       "2      Esta aplicaci√≥n esta padrisima ojala que asi f...   \n",
       "3                                          Muy divertida   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "62370                                                NaN   \n",
       "62371                                        Es un ascoo   \n",
       "62372                                                NaN   \n",
       "62373                                                NaN   \n",
       "62374                            Aaaaaaaaaaa super bueno   \n",
       "\n",
       "      Developer Reply Date and Time  Developer Reply Millis Since Epoch   \n",
       "0                               NaN                                 NaN  \\\n",
       "1                               NaN                                 NaN   \n",
       "2                               NaN                                 NaN   \n",
       "3                               NaN                                 NaN   \n",
       "4                               NaN                                 NaN   \n",
       "...                             ...                                 ...   \n",
       "62370                           NaN                                 NaN   \n",
       "62371                           NaN                                 NaN   \n",
       "62372                           NaN                                 NaN   \n",
       "62373                           NaN                                 NaN   \n",
       "62374                           NaN                                 NaN   \n",
       "\n",
       "      Developer Reply Text                                        Review Link  \n",
       "0                      NaN                                                NaN  \n",
       "1                      NaN  http://play.google.com/console/developers/4768...  \n",
       "2                      NaN  http://play.google.com/console/developers/4768...  \n",
       "3                      NaN  http://play.google.com/console/developers/4768...  \n",
       "4                      NaN                                                NaN  \n",
       "...                    ...                                                ...  \n",
       "62370                  NaN                                                NaN  \n",
       "62371                  NaN  http://play.google.com/console/developers/4768...  \n",
       "62372                  NaN                                                NaN  \n",
       "62373                  NaN                                                NaN  \n",
       "62374                  NaN  http://play.google.com/console/developers/4768...  \n",
       "\n",
       "[62375 rows x 16 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('combined.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your criteria (replace 'column_name' and 'desired_value' with your actual column and value)\n",
    "criteria = (df['Reviewer Language'] == 'en')\n",
    "\n",
    "# Use the criteria to filter the DataFrame\n",
    "df_eng = df[criteria]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Star Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>I luv memes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>This is the best app i love it</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Good now I can make my own meme</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62206</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62236</th>\n",
       "      <td>I hate it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62255</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62266</th>\n",
       "      <td>I love this app</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62355</th>\n",
       "      <td>Do u no de wae</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5777 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Review Text  Star Rating\n",
       "57                         I luv memes            4\n",
       "60                                 NaN            4\n",
       "79                                 NaN            4\n",
       "85      This is the best app i love it            5\n",
       "94     Good now I can make my own meme            5\n",
       "...                                ...          ...\n",
       "62206                              NaN            5\n",
       "62236                        I hate it            1\n",
       "62255                              NaN            4\n",
       "62266                  I love this app            5\n",
       "62355                   Do u no de wae            5\n",
       "\n",
       "[5777 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = ['Review Text','Star Rating']\n",
    "df_class = df_eng[selected_columns]\n",
    "df_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/9nczhhns0gx_03t4t5yv_z580000gn/T/ipykernel_2659/2434299613.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_class.dropna(subset=['Review Text'], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3365, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class.dropna(subset=['Review Text'], inplace=True)\n",
    "df_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review Text    0\n",
       "Star Rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_per_column = df_class.isnull().sum()\n",
    "missing_values_per_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'Review Text': 'reviews',\n",
    "    'Star Rating': 'target'\n",
    "}\n",
    "\n",
    "df_class = df_class.rename(columns=column_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>I would totally recommend this game to any of ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29000</th>\n",
       "      <td>Speechless</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22180</th>\n",
       "      <td>The best app ever way better than tik toc anyw...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>This is a good app but it doesnt let me post m...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15025</th>\n",
       "      <td>This app was great until the feature where you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>Everything was ok but suddenly I can't veiw ad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16121</th>\n",
       "      <td>Good</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62138</th>\n",
       "      <td>This game is fun I'll make so much memes XD je...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9914</th>\n",
       "      <td>I like it for memesüòÜ</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>Great app. Would be good to have notifications...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  target\n",
       "3997   I would totally recommend this game to any of ...       5\n",
       "29000                                         Speechless       5\n",
       "22180  The best app ever way better than tik toc anyw...       5\n",
       "1803   This is a good app but it doesnt let me post m...       4\n",
       "15025  This app was great until the feature where you...       1\n",
       "4972   Everything was ok but suddenly I can't veiw ad...       1\n",
       "16121                                               Good       5\n",
       "62138  This game is fun I'll make so much memes XD je...       3\n",
       "9914                                I like it for memesüòÜ       5\n",
       "1290   Great app. Would be good to have notifications...       4"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 3365 instances of 2 variables.\n",
      "It contains 361 1 star reviews (10.7% of all).\n",
      "It contains 75 2 star reviews (2.2% of all).\n",
      "It contains 136 3 star reviews (4.0% of all).\n",
      "It contains 266 4 star reviews (7.9% of all).\n",
      "It contains 2527 5 star reviews (75.1% of all).\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset contains {} instances of {} variables.\".format(df_class.shape[0], df_class.shape[1]))\n",
    "\n",
    "print(\n",
    "    \"It contains {} 1 star reviews ({:.1%} of all).\".format(\n",
    "        df_class[df_class.target == 1].shape[0],\n",
    "        df_class[df_class.target == 1].shape[0] / df_class.shape[0],\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"It contains {} 2 star reviews ({:.1%} of all).\".format(\n",
    "        df_class[df_class.target == 2].shape[0],\n",
    "        df_class[df_class.target == 2].shape[0] / df_class.shape[0],\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"It contains {} 3 star reviews ({:.1%} of all).\".format(\n",
    "        df_class[df_class.target == 3].shape[0],\n",
    "        df_class[df_class.target == 3].shape[0] / df_class.shape[0],\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"It contains {} 4 star reviews ({:.1%} of all).\".format(\n",
    "        df_class[df_class.target == 4].shape[0],\n",
    "        df_class[df_class.target == 4].shape[0] / df_class.shape[0],\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"It contains {} 5 star reviews ({:.1%} of all).\".format(\n",
    "        df_class[df_class.target == 5].shape[0],\n",
    "        df_class[df_class.target == 5].shape[0] / df_class.shape[0],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of negative review: \n",
      "    Really hard to work and it need better labels and it need a better upgrade pls don't get this app get a different one this one is not üíØ it confusing üòÇ\n",
      "    Garbage\n",
      "\n",
      "Examples of positive review: \n",
      "    Its soo good you can make memes and have fun and good times\n",
      "    its goodüëç because I like it\n"
     ]
    }
   ],
   "source": [
    "## Printing random samples of text from both the classes i.e. 1 star and \n",
    "print(\n",
    "    \"Examples of negative review: \\n    {}\\n    {}\".format(\n",
    "        df_class[df_class.target == 1].sample(1).reviews.iloc[0],\n",
    "        df_class[df_class.target == 1].sample(1).reviews.iloc[0],\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"\\nExamples of positive review: \\n    {}\\n    {}\".format(\n",
    "        df_class[df_class.target == 5].sample(1).reviews.iloc[0],\n",
    "        df_class[df_class.target == 5].sample(1).reviews.iloc[0],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset between train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_class[\"reviews\"], df_class[\"target\"], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45858    5\n",
       "11756    5\n",
       "57603    5\n",
       "14904    1\n",
       "17128    5\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer\n",
    "\n",
    "Transforming the text so that each word is a separate feature. Converting our text into sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the CountVectorizer to the training data\n",
    "vect = CountVectorizer().fit(X_train)\n",
    "\n",
    "# transform the documents in the training data to a document-term matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "# print(\"X_train_vectorized: \", X_train_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape = (2692,)\n",
      "Vocabulary length = 2931\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape = {}\".format(X_train.shape))\n",
    "print(\"Vocabulary length = {}\".format(len(vect.vocabulary_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in 2523 reviews CountVectorizer found 2791 different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jackintheblox', 1300),\n",
       " ('jailbreak', 1301),\n",
       " ('jam', 1302),\n",
       " ('jan', 1303),\n",
       " ('jane', 1304),\n",
       " ('jangan', 1305),\n",
       " ('jejejeje', 1306),\n",
       " ('jest', 1307),\n",
       " ('jiffy', 1308),\n",
       " ('jimtheantifurry', 1309),\n",
       " ('jisne', 1310),\n",
       " ('jk', 1311),\n",
       " ('jo', 1312),\n",
       " ('job', 1313),\n",
       " ('joe', 1314),\n",
       " ('jog', 1315),\n",
       " ('john', 1316),\n",
       " ('join', 1317),\n",
       " ('jojo', 1318),\n",
       " ('joke', 1319),\n",
       " ('jokeeee', 1320),\n",
       " ('jokes', 1321),\n",
       " ('joy', 1322),\n",
       " ('jsabmaker', 1323),\n",
       " ('judged', 1324),\n",
       " ('july', 1325),\n",
       " ('jus', 1326),\n",
       " ('just', 1327),\n",
       " ('justthinkguyyt', 1328),\n",
       " ('juvenile', 1329),\n",
       " ('karte', 1330),\n",
       " ('kat123k', 1331),\n",
       " ('katai', 1332),\n",
       " ('kayo', 1333),\n",
       " ('keep', 1334)]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at our vocabulary list (sorted alphabetically)\n",
    "# Does it look like you expected?\n",
    "sorted(vect.vocabulary_.items(), key=lambda x: x[1])[1300:1335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# with .toarray() the compressed sparse matrix form is converted to a normal numpy array\n",
    "print(X_train_vectorized.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulding pipeline with vectorized data and Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with CountVectorizer and Logistic Regression\n",
    "\n",
    "model = make_pipeline(CountVectorizer(), LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.52      0.54        62\n",
      "           2       0.25      0.05      0.09        19\n",
      "           3       0.17      0.10      0.13        29\n",
      "           4       0.60      0.18      0.28        66\n",
      "           5       0.83      0.96      0.89       497\n",
      "\n",
      "    accuracy                           0.78       673\n",
      "   macro avg       0.48      0.36      0.38       673\n",
      "weighted avg       0.74      0.78      0.74       673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC for Class 1: 0.91\n",
      "AUC-ROC for Class 2: 0.83\n",
      "AUC-ROC for Class 3: 0.78\n",
      "AUC-ROC for Class 4: 0.71\n",
      "AUC-ROC for Class 5: 0.86\n",
      "\n",
      "Average AUC-ROC: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Binarize the labels for each class\n",
    "y_test_bin = label_binarize(y_test, classes=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "\n",
    "# Calculate AUC-ROC for each class\n",
    "auc_scores = []\n",
    "for i in range(5):  # Assuming 5 classes\n",
    "    auc = roc_auc_score(y_test_bin[:, i], y_pred_prob[:, i])\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"AUC-ROC for Class {i + 1}: {auc:.2f}\")\n",
    "\n",
    "# You can also calculate the average AUC-ROC across all classes\n",
    "average_auc = sum(auc_scores) / len(auc_scores)\n",
    "print(f\"\\nAverage AUC-ROC: {average_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words with highest coefficients:\n",
      "             Coefficient\n",
      "worst           1.818223\n",
      "hate            1.707257\n",
      "garbage         1.511657\n",
      "sucks           1.430717\n",
      "useless         1.430051\n",
      "waste           1.229657\n",
      "isn             1.183869\n",
      "save            1.142975\n",
      "stupid          1.134883\n",
      "application     1.113925\n",
      "\n",
      "Top 10 words with lowest coefficients:\n",
      "       Coefficient\n",
      "nice     -1.344020\n",
      "good     -1.342794\n",
      "love     -1.260383\n",
      "best     -1.181174\n",
      "cool     -1.103045\n",
      "great    -1.092224\n",
      "like     -1.013085\n",
      "but      -1.007470\n",
      "fun      -0.991331\n",
      "funny    -0.989366\n"
     ]
    }
   ],
   "source": [
    "# Get the feature names from the CountVectorizer\n",
    "feature_names = model.named_steps['countvectorizer'].get_feature_names_out()\n",
    "\n",
    "# Get the coefficients from the trained Logistic Regression model\n",
    "coefficients = model.named_steps['logisticregression'].coef_\n",
    "\n",
    "# Create a DataFrame to associate feature names with their coefficients\n",
    "coef_df = pd.DataFrame(data=coefficients[0], index=feature_names, columns=['Coefficient'])\n",
    "\n",
    "# Sort the DataFrame to see words with the highest and lowest coefficients\n",
    "top_words = coef_df.sort_values(by='Coefficient', ascending=False).head(10)\n",
    "bottom_words = coef_df.sort_values(by='Coefficient', ascending=True).head(10)\n",
    "\n",
    "print(\"Top 10 words with highest coefficients:\")\n",
    "print(top_words)\n",
    "\n",
    "print(\"\\nTop 10 words with lowest coefficients:\")\n",
    "print(bottom_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stonks', 2310),\n",
       " ('stoot', 2311),\n",
       " ('stop', 2312),\n",
       " ('stopped', 2313),\n",
       " ('stops', 2314),\n",
       " ('storage', 2315),\n",
       " ('store', 2316),\n",
       " ('straight', 2317),\n",
       " ('stream', 2318),\n",
       " ('stress', 2319),\n",
       " ('stuck', 2320),\n",
       " ('stucks', 2321),\n",
       " ('stuff', 2322),\n",
       " ('stupid', 2323),\n",
       " ('stupidest', 2324),\n",
       " ('style', 2325),\n",
       " ('styles', 2326),\n",
       " ('sub', 2327),\n",
       " ('subs', 2328),\n",
       " ('subscrib', 2329)]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 15\n",
    "# This means a word should have been used in at least 15 SMS \n",
    "vect = TfidfVectorizer(min_df=1).fit(X_train)\n",
    "\n",
    "# transform the documents in the training data to a document-term matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "# let's look of some of the words gathered with this method\n",
    "sorted(vect.vocabulary_.items(), key=lambda x: x[1])[2310:2330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2931"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many words appear in more than 15 text messages\n",
    "len(sorted(vect.vocabulary_.items(), key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(TfidfVectorizer(), LogisticRegression(max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.37      0.46        62\n",
      "           2       0.00      0.00      0.00        19\n",
      "           3       0.00      0.00      0.00        29\n",
      "           4       0.14      0.02      0.03        66\n",
      "           5       0.78      0.98      0.87       497\n",
      "\n",
      "    accuracy                           0.76       673\n",
      "   macro avg       0.30      0.27      0.27       673\n",
      "weighted avg       0.64      0.76      0.69       673\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mac/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mac/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC for Class 1: 0.92\n",
      "AUC-ROC for Class 2: 0.91\n",
      "AUC-ROC for Class 3: 0.82\n",
      "AUC-ROC for Class 4: 0.72\n",
      "AUC-ROC for Class 5: 0.87\n",
      "\n",
      "Average AUC-ROC: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Binarize the labels for each class\n",
    "y_test_bin = label_binarize(y_test, classes=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Predict probabilities for each class\n",
    "y_pred_prob = model.predict_proba(X_test)\n",
    "\n",
    "# Calculate AUC-ROC for each class\n",
    "auc_scores = []\n",
    "for i in range(5):  # Assuming 5 classes\n",
    "    auc = roc_auc_score(y_test_bin[:, i], y_pred_prob[:, i])\n",
    "    auc_scores.append(auc)\n",
    "    print(f\"AUC-ROC for Class {i + 1}: {auc:.2f}\")\n",
    "\n",
    "# You can also calculate the average AUC-ROC across all classes\n",
    "average_auc = sum(auc_scores) / len(auc_scores)\n",
    "print(f\"\\nAverage AUC-ROC: {average_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest tfidf:\n",
      "['ùöùùöëùöé' 'ùôæùöÉùô∑ùô¥ùöÅ' 'ùôæùôΩùô¥' 'ùôæùôΩ' 'ùôªùô∏ùöÉùô¥ùöÅùô∞ùôªùôªùöà' 'ùô∏ùôΩ' 'ùôµùöÑùô≤ùô∫' 'ùôøùô∏ùô≤ùöÉùöÑùöÅùô¥ùöÇ' 'ùô¥ùöÖùô¥ùôΩ'\n",
      " 'ùô≤ùôæùôΩùôΩùô¥ùô≤ùöÉ']\n",
      "\n",
      "Largest tfidf: \n",
      "['osam' 'bekar' 'yeeeey' 'lo' 'yaiy' 'sheesh' 'xd' 'wut' 'wunderbar'\n",
      " 'good']\n"
     ]
    }
   ],
   "source": [
    "# save all feature names == words in an array\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "\n",
    "#sort for the column names according to highest tfidf value in the column\n",
    "sorted_tfidf_index = X_train_vectorized.toarray().max(0).argsort()\n",
    "\n",
    "# print words with highest and lowest tfidf values\n",
    "print(\"Smallest tfidf:\\n{}\\n\".format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print(\"Largest tfidf: \\n{}\".format(feature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stremming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing stemmer and countvectorizer \n",
    "stemmer = nltk.PorterStemmer()\n",
    "cv_analyzer = CountVectorizer().build_analyzer()\n",
    "# tfidf_analyzer = TfidfVectorizer(min_df=15).build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in cv_analyzer(doc))\n",
    "\n",
    "# define CountVectorizer with stemming function \n",
    "stem_vectorizer = CountVectorizer(analyzer = stemmed_words)\n",
    "#stem_vectorizer = TfidfVectorizer(min_df=15, analyzer = stemmed_words)\n",
    "\n",
    "\n",
    "# Transform X_train\n",
    "X_train_stem_vectorized = stem_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "872",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 872",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/mac/Spiced/Projects/reveiws-prediction/prediction.ipynb Cell 38\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Spiced/Projects/reveiws-prediction/prediction.ipynb#Y126sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sample_text \u001b[39m=\u001b[39m X_train[:\u001b[39m1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mac/Spiced/Projects/reveiws-prediction/prediction.ipynb#Y126sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSample Text - \u001b[39m\u001b[39m\"\u001b[39m, sample_text[\u001b[39m872\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Spiced/Projects/reveiws-prediction/prediction.ipynb#Y126sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m30\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mac/Spiced/Projects/reveiws-prediction/prediction.ipynb#Y126sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mText after passing through build_analyzer - \u001b[39m\u001b[39m\"\u001b[39m, cv_analyzer(sample_text[\u001b[39m872\u001b[39m]))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1118\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 872"
     ]
    }
   ],
   "source": [
    "sample_text = X_train[:1]\n",
    "print(\"Sample Text - \", sample_text[872])\n",
    "print(\"-\"*30)\n",
    "print(\"Text after passing through build_analyzer - \", cv_analyzer(sample_text[872]))\n",
    "print(\"-\"*30)\n",
    "print(\"Text after stemming - \",[stemmer.stem(w) for w in cv_analyzer(sample_text[872])])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
